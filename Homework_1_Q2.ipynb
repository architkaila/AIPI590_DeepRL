{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpFZ-Uzp7MpI"
      },
      "source": [
        "## AIPI 590 (Deep Reinforecement Learning) HOMEWORK 1, Question 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NAME = \"Archit Kaila\"\n",
        "COLLABORATORS = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 1.2: Train an agent to play any game/task in SB3 using A2C with Colab. Use the APIs provided in SB3 to run the Google Colab experiments and to train/test the RL agent.\n",
        "#### Requirements:\n",
        "    - Pick a task/game in SB3.\n",
        "    - Add a TensorBoard to visualize the training curves.   \n",
        "    - Include/record the final evaluation video.\n",
        "    - Saving/loading the policy/model.\n",
        "#### Submission:\n",
        "    - Submit a Colab notebook including the training/testing\n",
        "    - experiments and results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Install Stable Baseline3 And Other Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyrjTV7F7Pf0",
        "outputId": "28511897-e8bd-422f-9f4c-5cb034a7b61e"
      },
      "outputs": [],
      "source": [
        "## Stable Baseline3 Installation\n",
        "!pip install stable-baselines3[extra] \n",
        "\n",
        "## visualization requirment\n",
        "!apt-get install ffmpeg freeglut3-dev xvfb\n",
        "!pip install pyglet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jO7HxwG57cj0"
      },
      "outputs": [],
      "source": [
        "## Library Imports\n",
        "import gym\n",
        "import numpy as np\n",
        "from stable_baselines3 import A2C\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating a GYM environment and instanciating an agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HChVTba8Y_f",
        "outputId": "6459d89e-7844-4d2f-9283-b52134f50d7c"
      },
      "outputs": [],
      "source": [
        "## Create a GYM environment of CartPole-v1\n",
        "environment = gym.make('CartPole-v1')\n",
        "\n",
        "## initialize tensorboard log directory\n",
        "tensorboard_logs = \"data/tb/\"\n",
        "\n",
        "## Initialize an Agent (Actor Critic)\n",
        "model = A2C('MlpPolicy', environment, verbose=1, normalize_advantage=True, tensorboard_log=tensorboard_logs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Intialize environment for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dkNgkCs8duM",
        "outputId": "2be0d47d-9fa0-4319-e7d5-e1241760eaf1"
      },
      "outputs": [],
      "source": [
        "## Create environment for evaluation\n",
        "evaluation_environment = gym.make('CartPole-v1')\n",
        "\n",
        "## Setting up agent with randomly before training with #eval episodes = 100\n",
        "reward_mean, reward_std = evaluate_policy(model, evaluation_environment, n_eval_episodes=100)\n",
        "\n",
        "print(f'Initial Mean Reward: {np.round(reward_mean,2)} +/- {np.round(reward_std,2)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Agent Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGEc_Duj8ht7",
        "outputId": "6310eb9a-4205-4797-8f67-9e56a39aab68"
      },
      "outputs": [],
      "source": [
        "## Initialize Train loop for the agent with 500k steps\n",
        "model.learn(total_timesteps=500000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Agent Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Estimating rewards and evaluating our trained agent\n",
        "reward_mean, reward_std = evaluate_policy(model, evaluation_environment, n_eval_episodes=100)\n",
        "\n",
        "print(f'Mean Reward: {np.round(reward_mean,2)} +/- {np.round(reward_std,2)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup environment to play and record Video inside Colab notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSLl-DI88mbp"
      },
      "outputs": [],
      "source": [
        "## Setup a dummy display\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function to Record Agent Actions In Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZjojsMM8ya4"
      },
      "outputs": [],
      "source": [
        "## Function to record video of agent\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
        "\n",
        "def video_recorder(environment_id, model, video_length=500, prefix='', video_destination='videos/'):\n",
        "  ## Creating dummy environment\n",
        "  evaluation_env = DummyVecEnv([lambda: gym.make(environment_id)])\n",
        "  \n",
        "  ## Starting the video at step=0 and recording the next 500 steps\n",
        "  evaluation_env = VecVideoRecorder(evaluation_env, video_folder=video_destination,\n",
        "                              record_video_trigger=lambda step: step == 0, video_length=video_length,\n",
        "                              name_prefix=prefix)\n",
        "\n",
        "  ## Iterating and executing actions\n",
        "  obs = evaluation_env.reset()\n",
        "  for _ in range(video_length):\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, _, _, _ = evaluation_env.step(action)\n",
        "\n",
        "  ## Closing video recorder\n",
        "  evaluation_env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions To Render and Display Video Frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qau_14-o81lG"
      },
      "outputs": [],
      "source": [
        "## Function to show video play inside the notebook\n",
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "def show_videos(video_path='', prefix=''):\n",
        "  \"\"\"\n",
        "  Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "  :param video_path: (str) Path to the folder containing videos\n",
        "  :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "  \"\"\"\n",
        "  html = []\n",
        "  for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "      video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "      html.append('''<video alt=\"{}\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "  ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vizualizing Video Recording Of Our Trained Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "CgLLDlWt84LO",
        "outputId": "a68bc25e-4369-4131-ec1b-8f72a0139ac3"
      },
      "outputs": [],
      "source": [
        "## Calling the video_recording function to record the agent actions\n",
        "video_recorder('CartPole-v1', model, video_length=500, prefix='a2c-cartpole')\n",
        "\n",
        "## Display recorded video inline\n",
        "show_videos('videos', prefix='a2c')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tensorboard Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zeg8nc-jHowK"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./data/tb/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
